{"application": "echo", "expectedArtifacts": [{"defaultArtifact": {"artifactAccount": "docker-registry", "id": "6e1ad720-7d9b-41d4-867b-797099977ca8", "name": "gcr.io/ua-ops-artifacts/echo", "reference": "gcr.io/ua-ops-artifacts/echo:latest", "type": "docker/image", "version": "latest"}, "displayName": "echo", "id": "0690d03e-b74a-46cb-9d34-a279485f24e8", "matchArtifact": {"artifactAccount": "docker-registry", "id": "09cffd7c-7caf-4681-b6b2-7227f78f3c5f", "name": "gcr.io/ua-ops-artifacts/echo", "type": "docker/image"}, "useDefaultArtifact": true, "usePriorArtifact": false}, {"defaultArtifact": {"artifactAccount": "urbanairship-github", "id": "75ccd620-33c6-4c43-9d08-5e3c242660e6", "name": "services/echo.yaml", "reference": "https://api.github.com/repos/urbanairship/gcp-infrastructure/contents/services/echo.yaml", "type": "github/file", "version": "master"}, "displayName": "echo.yaml", "id": "38272987-34a5-430b-bd47-c78dc46efeef", "matchArtifact": {"artifactAccount": "urbanairship-github", "id": "d901436c-d8fc-4c51-8aa2-d5c0915fdae1", "name": "services/echo.yaml", "type": "github/file"}, "useDefaultArtifact": true, "usePriorArtifact": false}], "id": "125c8835-e142-4b19-8df7-25e99f76c8b8", "index": 10, "keepWaitingPipelines": false, "lastModifiedBy": "scott.frazier@airship.com", "limitConcurrent": true, "name": "Rolling Deploy V2", "notifications": [{"address": "test-spinnaker", "level": "pipeline", "type": "slack", "when": ["pipeline.starting", "pipeline.complete", "pipeline.failed"]}], "parameterConfig": [], "schema": "1", "stages": [{"clusters": [{"account": "ua-ops-transitional-stag-acct", "application": "echo", "associatePublicIpAddress": true, "authScopes": ["cloud-platform"], "automaticRestart": true, "availabilityZones": {"us-east1": ["us-east1-b", "us-east1-c", "us-east1-d"]}, "backendServiceMetadata": ["echo-bes"], "backendServices": {}, "canIpForward": false, "capacity": {"desired": 3, "max": 3, "min": 3}, "cloudProvider": "gce", "disableTraffic": false, "disks": [{"sizeGb": 10, "type": "pd-standard"}], "distributionPolicy": {"zones": []}, "enableIntegrityMonitoring": false, "enableSecureBoot": false, "enableVtpm": false, "imageSource": "priorStage", "instanceMetadata": {"backend-service-names": "echo-bes", "cos-update-strategy": "update_disabled", "deployment-image": "echo:latest", "global-load-balancer-names": "echo-l7lb", "prometheus_io_path": "/metrics", "prometheus_io_port": "9090", "prometheus_io_scrape": "true", "service": "echo", "user-data": "#cloud-config\n\nusers:\n- name: echo\n  groups: docker\n  uid: 2000\n- name: node-exporter\n  groups: docker\n  uid: 3000\n- name: fluentd\n  groups: docker\n  uid: 3001\nwrite_files:\n- path: /etc/docker/daemon.json\n  content: |-\n    {\n                  \"log-driver\": \"journald\",\n                  \"disable-legacy-registry\": true,\n                  \"live-restore\": true,\n                  \"storage-driver\": \"overlay2\"\n                }\n  owner: root\n  permissions: 644\n- path: /etc/ua-firewall\n  content: |-\n    #!/bin/bash\n    iptables -w -A INPUT -p tcp --dport 9090 -j ACCEPT # rash\n    iptables -w -A INPUT -p tcp --dport 9100 -j ACCEPT # node_exporter\n    iptables -w -A INPUT -p tcp --dport 9101 -j ACCEPT # fluentd\n    iptables -w -A INPUT -p tcp --dport 17001 -j ACCEPT # jmx\n    iptables -w -A INPUT -p tcp --dport 17003 -j ACCEPT # ua healthcheck\n    iptables -w -A INPUT -p tcp --dport 17004 -j ACCEPT # ua probe\n    iptables -w -A INPUT -p tcp --dport 8080 -j ACCEPT # echo\n  owner: root\n  permissions: '0744'\n- path: /etc/systemd/system/firewall.service\n  content: |\n    [Unit]\n    Description=Firewall(iptables) service\n    Before=network-pre.target\n    Wants=network-pre.target\n\n    [Service]\n    Type=oneshot\n    ExecStart=/etc/ua-firewall\n\n    [Install]\n    WantedBy=multi-user.target\n  owner: root\n  permissions: '0644'\n- path: /etc/systemd/system/fluentd.service\n  content: |\n    [Unit]\n    Description=Docker container for fluentd\n    Requires=network.target docker.service\n    Wants=fluentd.service\n    After=network.target docker.service fluentd.service\n\n    [Service]\n    User=fluentd\n    Restart=always\n    # Make sure the $HOME/.docker directory is writeable\n    Environment=\"HOME=/home/fluentd\"\n    ExecStartPre=/usr/bin/docker-credential-gcr configure-docker\n    # This is non-optional due to some timeout shit I don't understand\n    # Docker's low timeout causes the ExecStart to fail when pulling\n    # the external image before the network is really ready. However,\n    # curl is happy to wait until the network is up and operational.\n    ExecStartPre=/usr/bin/curl -s https://gcr.io/v1/_ping\n    ExecStartPre=-/usr/bin/docker kill 'fluentd'\n    ExecStartPre=-/usr/bin/docker rm 'fluentd'\n    ExecStart=/usr/bin/docker run --rm --name='fluentd' \\\n        -v /usr/lib64:/host/lib:ro \\\n        -v /var/log:/var/log:rw \\\n        -v /var/lib/docker/containers:/var/lib/docker/containers:ro \\\n        -v /etc/fluent/config.d/:/etc/fluent/config.d/:ro \\\n        --net=host \\\n        gcr.io/google_containers/fluentd-gcp:2.0.18\n    ExecStop=/usr/bin/docker stop -t 10 'fluentd'\n\n    [Install]\n    WantedBy=multi-user.target\n  owner: root\n  permissions: '0644'\n- path: /etc/fluent/config.d/containers.input.conf\n  content: |\n    <source>\n      type systemd\n      # docker appears to dupe everything that services log, but does so with more\n      # metadata, so lets just use that for now\n      filters [{ \"_SYSTEMD_UNIT\": \"docker.service\"}]\n      pos_file /var/log/containers.pos\n      read_from_head true\n      tag containers\n    </source>\n    <filter containers.**>\n      @type grep\n      # exclude shit from fluentd so we don't loop infinitely\n      <exclude>\n        key CONTAINER_NAME\n        pattern fluentd\n      </exclude>\n    </filter>\n    <filter containers.**>\n      @type parser\n      # try parsing as json, then just copy it through if it fails\n      key_name MESSAGE\n      format json\n      reserve_data true\n      suppress_parse_error_log true\n      time_parse false\n    </filter>\n    # break this glass if you're diagnosing issues sending to stackdriver\n    # it'll make all output appear in journalctl -b -u fluentd\n    #<match **>\n    #  @type stdout\n    #</match>\n  owner: root\n- path: /etc/fluent/config.d/monitoring.conf\n  content: |\n    # Prometheus monitoring\n    <source>\n      @type prometheus\n      port 9101\n    </source>\n    <source>\n      @type prometheus_monitor\n    </source>\n  owner: root\n- path: /etc/fluent/config.d/output.conf\n  content: |\n    <match containers.**>\n      @type copy\n      <store>\n        @type google_cloud\n        detect_subservice false\n        # Set the buffer type to file to improve the reliability and reduce the\n        # memory consumption\n        buffer_type file\n        buffer_path /var/log/fluentd-buffers/kubernetes.containers.buffer\n        # Set queue_full action to block because we want to pause gracefully\n        # in case of the off-the-limits load instead of throwing an exception\n        buffer_queue_full_action block\n        # Set the chunk limit conservatively to avoid exceeding the GCL limit\n        # of 10MiB per write request.\n        buffer_chunk_limit 2M\n        # Cap the combined memory usage of this buffer and the one below to\n        # 2MiB/chunk * (6 + 2) chunks = 16 MiB\n        buffer_queue_limit 6\n        # Never wait more than 5 seconds before flushing logs in the non-error case\n        flush_interval 5s\n        # Never wait longer than 30 seconds between retries.\n        max_retry_wait 30\n        # Disable the limit on the number of retries (retry forever).\n        disable_retry_limit\n        # Use multiple threads for processing.\n        num_threads 2\n      </store>\n      <store>\n        @type prometheus\n        <metric>\n          type counter\n          name logging_entry_count\n          desc Total number of log entries from either app containers or system\n          <labels>\n            component container\n          </labels>\n        </metric>\n      </store>\n    </match>\n    <match kernel>\n      @type copy\n      <store>\n        @type google_cloud\n        detect_subservice false\n        buffer_type file\n        buffer_path /var/log/fluentd-buffers/kernel.buffer\n        buffer_queue_full_action block\n        buffer_chunk_limit 2M\n        buffer_queue_limit 2\n        flush_interval 10s\n        max_retry_wait 60\n        disable_retry_limit\n        num_threads 1\n      </store>\n    </match>\n  owner: root\n- path: /etc/fluent/config.d/system.input.conf\n  content: |\n    <source>\n      type tail\n      format syslog\n      path /var/log/startupscript.log\n      pos_file /var/log/gcp-startupscript.log.pos\n      tag startupscript\n    </source>\n    <source>\n      type systemd\n      filters [{ \"_TRANSPORT\": \"kernel\" }]\n      pos_file /var/log/kernel.pos\n      tag kernel\n    </source>\n  owner: root\n- path: /etc/systemd/system/node_exporter.service\n  content: |\n    [Unit]\n    Description=Docker container for node_exporter\n    Requires=network.target docker.service\n    Wants=fluentd.service\n    After=network.target docker.service fluentd.service\n\n    [Service]\n    User=node-exporter\n    Restart=always\n    # Make sure the $HOME/.docker directory is writeable\n    Environment=\"HOME=/home/node-exporter\"\n    ExecStartPre=/usr/bin/docker-credential-gcr configure-docker\n    # This is non-optional due to some timeout shit I don't understand\n    # Docker's low timeout causes the ExecStart to fail when pulling\n    # the external image before the network is really ready. However,\n    # curl is happy to wait until the network is up and operational.\n    ExecStartPre=/usr/bin/curl -s https://gcr.io/v1/_ping\n    ExecStartPre=-/usr/bin/docker kill 'node_exporter'\n    ExecStartPre=-/usr/bin/docker rm 'node_exporter'\n    ExecStart=/usr/bin/docker run --rm --name='node_exporter' \\\n        -v /proc:/host/proc:ro \\\n        -v /sys:/host/sys:ro \\\n        -v /:/rootfs:ro \\\n        --net=host \\\n        prom/node-exporter:v0.14.0 -collector.procfs /host/proc -collector.sysfs /host/sys -collector.filesystem.ignored-mount-points \"^/(sys|proc|dev|host|etc)($|/)\"\n    ExecStop=/usr/bin/docker stop -t 10 'node_exporter'\n\n    [Install]\n    WantedBy=multi-user.target\n  owner: root\n  permissions: '0644'\n- path: /etc/default/echo\n  content: ''\n  owner: root\n  permissions: '0644'\n- path: /etc/systemd/system/echo.service\n  content: \"[Unit]\\nDescription=Docker container for echo\\nRequires=network.target\\\n    \\ docker.service\\nWants=fluentd.service\\nAfter=network.target docker.service fluentd.service\\n\\\n    \\n[Service]\\nUser=echo\\nRestart=always\\n# Make sure the $HOME/.docker directory\\\n    \\ is writeable\\nEnvironment=\\\"HOME=/home/echo\\\"\\nExecStartPre=/usr/bin/docker-credential-gcr\\\n    \\ configure-docker\\n# This is non-optional due to some timeout shit I don't understand\\n\\\n    # Docker's low timeout causes the ExecStart to fail when pulling\\n# the external\\\n    \\ image before the network is really ready. However,\\n# curl is happy to wait\\\n    \\ until the network is up and operational.\\nExecStartPre=/usr/bin/curl -s https://gcr.io/v1/_ping\\n\\\n    ExecStartPre=-/usr/bin/docker kill 'echo'\\nExecStartPre=-/usr/bin/docker rm 'echo'\\n\\\n    ExecStart=/usr/bin/docker run --rm --name='echo' \\\\\\n    --net host \\\\\\n    --stop-timeout\\\n    \\ 70 \\\\\\n    --env-file='/etc/default/echo' \\\\\\n    gcr.io/ua-ops-artifacts/echo:latest\\\n    \\ \\nExecStop=/usr/bin/docker stop -t 70 'echo'\\n\\n[Install]\\nWantedBy=multi-user.target\\n\"\n  owner: root\n  permissions: '0644'\nruncmd:\n- systemctl restart docker.service\n- systemctl daemon-reload\n- systemctl start firewall.service\n- systemctl daemon-reload\n- systemctl start fluentd.service\n- systemctl enable fluentd.service\n- systemctl daemon-reload\n- systemctl start node_exporter.service\n- systemctl enable node_exporter.service\n- systemctl daemon-reload\n- systemctl start echo.service\n- systemctl enable echo.service\n", "version": "latest"}, "instanceType": "f1-micro", "labels": {"component": "echo", "department": "infrastructure", "operator": "infrastructure", "product": "all"}, "loadBalancers": [], "loadBalancingPolicy": {"balancingMode": "UTILIZATION", "capacityScaler": 1, "maxUtilization": 0.8, "namedPorts": [{"name": "echo-http", "port": 8080}]}, "minCpuPlatform": "", "network": "base-network", "onHostMaintenance": "MIGRATE", "overwriteAncestorAutoHealingPolicy": false, "preemptible": false, "provider": "gce", "region": "us-east1", "regional": true, "selectZones": false, "serviceAccountEmail": "echo-service@ua-ops-transitional-stag.iam.gserviceaccount.com", "stack": "stag", "strategy": "", "subnet": "base-subnetwork-us-east1", "tags": ["echo-service", "echo-ashc-spinnaker-1569453814742"], "targetSize": 3, "userData": ""}], "failOnFailedExpressions": true, "name": "Deploy", "refId": "2", "requisiteStageRefIds": ["4"], "stageTimeoutMs": 1800000, "type": "deploy"}, {"cloudProvider": "gce", "cloudProviderType": "gce", "failOnFailedExpressions": true, "name": "Find Image from Tags", "packageName": "cos-stable-76-12239-60-0", "refId": "4", "regions": [], "requisiteStageRefIds": [], "tags": {}, "type": "findImageFromTags"}, {"cloudProvider": "gce", "cloudProviderType": "gce", "cluster": "echo-stag", "credentials": "ua-ops-transitional-stag-acct", "failOnFailedExpressions": true, "moniker": {"app": "echo", "cluster": "echo-stag", "stack": "stag"}, "name": "Destroy Server Group", "refId": "5", "regions": ["us-east1"], "requisiteStageRefIds": ["2"], "target": "ancestor_asg_dynamic", "type": "destroyServerGroup"}], "triggers": [], "updateTs": "1600387483753"}